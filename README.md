# Chat with Large Language Models

This repository hosts a lightweight Streamlit-based application designed for seamless interaction with Large Language Models (LLMs) using the Ollama library. The app provides an intuitive interface for sending queries and receiving instant responses from a language model.

## Key Features
- **Real-Time Chat:** Engage in conversations with LLMs and receive responses instantly.
- **Simple and Intuitive UI:** Built with Streamlit to ensure a user-friendly experience.

---

## Setup and Installation

### Clone the Repository
To get started, clone this repository to your local machine:
```bash
git clone https://github.com/shyr1es/Advanced-Programming-Nurda-Dima-Ernur-.git
cd streamlit-llm-chat
```
### Set Up a Virtual Environment
Create and activate a virtual environment to manage dependencies:
For Linux/Mac:
```bash
python -m venv venv  
source venv/bin/activate  
```
For Windows:
```bash
python -m venv venv  
venv\Scripts\activate  
```

### Install Dependencies
Install all the required libraries by running:
```bash
pip install -r requirements.txt
```

### How to Use
Launch the Application
Run the Streamlit app with the following command:
```bash
streamlit run src/app.py
```
### Access the App
Open your browser and navigate to:
```bash
http://localhost:8501
```


